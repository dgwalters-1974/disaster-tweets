# TWEET-CLASSIFICATION
This notebook contains:
1. A Jupyter notebook which runs the tiny-BERT model on a dataset of tweets. Text inputs are categorised as either 'disaster' or 'general' depending on their content. The model is saved and uploaded to AWS. Run all cells in the Jupyter notebook first to save the tweet classificatioin model to the cloud.
2. A Python file (inc. dependencies) which uses AWS and FastAPI together to download and serve the previous model.

This method follows that given in the 2025 Deploy ML Model in Production with FastAPI and Docker course by Laxmi Kant.
